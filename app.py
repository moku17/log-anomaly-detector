import streamlit as st
import pandas as pd
import re
from datetime import datetime
from sklearn.ensemble import IsolationForest
import matplotlib.pyplot as plt
from io import StringIO

# ë¡œê·¸ íŒŒì‹± í•¨ìˆ˜
def parse_log_line(line):
    pattern = r'(?P<ip>\S+) - - \[(?P<datetime>[^\]]+)\] "(?P<method>\S+) (?P<url>\S+) \S+" (?P<status>\d{3}) (?P<size>\d+)'
    match = re.match(pattern, line)
    if match:
        data = match.groupdict()
        data['datetime'] = datetime.strptime(data['datetime'], '%d/%b/%Y:%H:%M:%S %z')
        return data
    return None

def load_logs_from_text(text):
    lines = text.split('\n')
    parsed = [parse_log_line(line) for line in lines if parse_log_line(line)]
    return pd.DataFrame(parsed)

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ì´ìƒí–‰ìœ„ íƒì§€ê¸°", layout="wide")
st.title("ğŸ•µï¸â€â™‚ï¸ ì´ìƒí–‰ìœ„ íƒì§€ ì‹œìŠ¤í…œ (Isolation Forest)")

# íŒŒì¼ ì—…ë¡œë“œ
uploaded_file = st.file_uploader("ğŸ”½ ë¡œê·¸ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš” (.log í˜•ì‹)", type=["log", "txt"])

if uploaded_file is not None:
    # ë¡œê·¸ ì½ê¸°
    stringio = StringIO(uploaded_file.getvalue().decode("utf-8"))
    df = load_logs_from_text(stringio.read())

    if df.empty:
        st.warning("âš ï¸ ë¡œê·¸ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    else:
        st.success("âœ… ë¡œê·¸ íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
        grouped = df.groupby('ip')

        # íŠ¹ì§• ì¶”ì¶œ
        feature_df = grouped.size().reset_index(name='request_count')
        feature_df['unique_urls'] = grouped['url'].nunique().values
        feature_df['error_rate'] = grouped.apply(lambda x: (x['status'] != '200').mean()).values
        feature_df['avg_size'] = grouped['size'].apply(lambda x: x.astype(int).mean()).values

        # ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡
        model = IsolationForest(contamination=0.2, random_state=42)
        model.fit(feature_df[['request_count', 'unique_urls', 'error_rate', 'avg_size']])
        feature_df['anomaly'] = model.predict(feature_df[['request_count', 'unique_urls', 'error_rate', 'avg_size']])

        # ê²°ê³¼ ì¶œë ¥
        st.subheader("ğŸ“Š IPë³„ ìš”ì²­ ë¶„ì„ ê²°ê³¼")
        st.dataframe(feature_df)

        # ì´ìƒí–‰ìœ„ë§Œ í‘œì‹œ
        st.subheader("ğŸš¨ ì´ìƒí–‰ìœ„ë¡œ íƒì§€ëœ IP")
        st.dataframe(feature_df[feature_df['anomaly'] == -1])

        # ê·¸ë˜í”„
        st.subheader("ğŸ“ˆ ì´ìƒí–‰ìœ„ ì‹œê°í™”")
        fig, ax = plt.subplots(figsize=(10, 4))
        bar_color = feature_df['anomaly'].map({-1: 'red', 1: 'blue'})
        ax.bar(feature_df['ip'], feature_df['request_count'], color=bar_color)
        ax.set_title("IPë³„ ìš”ì²­ ìˆ˜ (ë¹¨ê°„ìƒ‰ = ì´ìƒí–‰ìœ„)")
        ax.set_ylabel("ìš”ì²­ ìˆ˜")
        ax.set_xticklabels(feature_df['ip'], rotation=45)
        st.pyplot(fig)