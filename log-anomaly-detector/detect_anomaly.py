import pandas as pd
from parse_logs import load_logs
from sklearn.ensemble import IsolationForest
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report

# ë¡œê·¸ ì½ê¸°
df = load_logs("access.log")

# ê¸°ë³¸ íŠ¹ì§• ë§Œë“¤ê¸°
grouped = df.groupby('ip')

feature_df = grouped.size().reset_index(name='request_count')  # ìš”ì²­ ìˆ˜
feature_df['unique_urls'] = grouped['url'].nunique().values    # ìš”ì²­í•œ URL ì¢…ë¥˜ ìˆ˜
feature_df['error_rate'] = grouped.apply(lambda x: (x['status'] != '200').mean()).values  # ì˜¤ë¥˜ ë¹„ìœ¨
feature_df['avg_size'] = grouped['size'].apply(lambda x: x.astype(int).mean()).values  # í‰ê·  ì‘ë‹µ í¬ê¸°

# AI ëª¨ë¸
model = IsolationForest(contamination=0.2, random_state=42)
model.fit(feature_df[['request_count', 'unique_urls', 'error_rate', 'avg_size']])
feature_df['anomaly'] = model.predict(feature_df[['request_count', 'unique_urls', 'error_rate', 'avg_size']])

# Step 2: ì„±ëŠ¥ í‰ê°€ìš© ë¼ë²¨ë§Œë“¤ê¸°
# ì˜ˆë¥¼ ë“¤ì–´ 192.168.0.1ì€ ê³µê²©ì(ì´ìƒí–‰ìœ„)ë¼ê³  ê°€ì •
feature_df['true_label'] = feature_df['ip'].apply(lambda x: -1 if x == '192.168.0.1' else 1)

# í‰ê°€ ì§€í‘œ ì¶œë ¥
print("\nğŸ“Œ Classification Report:")
print(classification_report(feature_df['true_label'], feature_df['anomaly'], target_names=['ì •ìƒ', 'ì´ìƒ']))

# íƒì§€ ê²°ê³¼ ì¶œë ¥
print("\nğŸ“Š ì „ì²´ íŠ¹ì§• + ì´ìƒ ì—¬ë¶€:")
print(feature_df)

print("\nğŸš¨ ì´ìƒí–‰ìœ„ë¡œ íƒì§€ëœ IP:")
print(feature_df[feature_df['anomaly'] == -1])

# ì‹œê°í™”
plt.figure(figsize=(8, 4))
plt.bar(feature_df['ip'], feature_df['request_count'], color=(feature_df['anomaly'] == -1).map({True: 'red', False: 'blue'}))
plt.title("IPë³„ ìš”ì²­ ìˆ˜ (ë¹¨ê°„ìƒ‰ = ì´ìƒí–‰ìœ„)")
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()